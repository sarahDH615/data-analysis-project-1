{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies, and pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "pytrends = TrendReq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty &amp; Fitness</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Books &amp; Literature</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business &amp; Industrial</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category  category_id\n",
       "0   Arts & Entertainment            3\n",
       "1       Autos & Vehicles           47\n",
       "2       Beauty & Fitness           44\n",
       "3     Books & Literature           22\n",
       "4  Business & Industrial           12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the csv of all the categories\n",
    "path = 'categories.csv'\n",
    "categs_df = pd.read_csv(path)\n",
    "categs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Ark.</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Calif.</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Abbrev Code\n",
       "0     Alabama    Ala.   AL\n",
       "1      Alaska  Alaska   AK\n",
       "2     Arizona   Ariz.   AZ\n",
       "3    Arkansas    Ark.   AR\n",
       "4  California  Calif.   CA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the csv of the state abbreviations\n",
    "states_path = 'statesAbbrev.csv'\n",
    "states_abbrev_df = pd.read_csv(states_path)\n",
    "states_abbrev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a list of the state abbreviations with the country code added in\n",
    "abbrev_list = [f\"US-{x}\" for x in states_abbrev_df['Code']]\n",
    "len(abbrev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US-AL',\n",
       " 'US-AK',\n",
       " 'US-AZ',\n",
       " 'US-AR',\n",
       " 'US-CA',\n",
       " 'US-CO',\n",
       " 'US-CT',\n",
       " 'US-DE',\n",
       " 'US-DC',\n",
       " 'US-FL',\n",
       " 'US-GA',\n",
       " 'US-HI',\n",
       " 'US-ID',\n",
       " 'US-IL',\n",
       " 'US-IN',\n",
       " 'US-IA',\n",
       " 'US-KS',\n",
       " 'US-KY',\n",
       " 'US-LA',\n",
       " 'US-ME',\n",
       " 'US-MD',\n",
       " 'US-MA',\n",
       " 'US-MI',\n",
       " 'US-MN',\n",
       " 'US-MS',\n",
       " 'US-MO',\n",
       " 'US-MT',\n",
       " 'US-NE',\n",
       " 'US-NV',\n",
       " 'US-NH',\n",
       " 'US-NJ',\n",
       " 'US-NM',\n",
       " 'US-NY',\n",
       " 'US-NC',\n",
       " 'US-ND',\n",
       " 'US-OH',\n",
       " 'US-OK',\n",
       " 'US-OR',\n",
       " 'US-PA',\n",
       " 'US-RI',\n",
       " 'US-SC',\n",
       " 'US-SD',\n",
       " 'US-TN',\n",
       " 'US-TX',\n",
       " 'US-UT',\n",
       " 'US-VT',\n",
       " 'US-VA',\n",
       " 'US-WA',\n",
       " 'US-WV',\n",
       " 'US-WI',\n",
       " 'US-WY']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbrev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list for all the category ids\n",
    "cat_list = [x for x in categs_df['category_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list for all the category names\n",
    "cat_name_list = [x for x in categs_df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of columns to go into each state's df\n",
    "columns_list = ['time'] + cat_name_list\n",
    "#columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict to hold all the different state info on all the categories\n",
    "statesinfo_df_dict = {}\n",
    "for state in abbrev_list:\n",
    "    statesinfo_df_dict[state] = pd.DataFrame(columns=columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of dict: should be same as len of abbrev_list\n",
    "len(statesinfo_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing a test df for one state\n",
    "#print(abbrev_list[27])\n",
    "#statesinfo_df_dict[abbrev_list[27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kw_list = '*'\n",
    "\n",
    "#def per_state_info_collector(state):\n",
    "    #for x in range(0, len(cat_name_list)):\n",
    "        #try:\n",
    "            #pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2020-12-20', geo=state)\n",
    "            #state_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            #state_interest_df.reset_index(level=0, inplace=True)\n",
    "            #statesinfo_df_dict[state]['time'] = state_interest_df['date']\n",
    "            #statesinfo_df_dict[state][f'{cat_name_list[x]}'] = state_interest_df['*']\n",
    "            #output_path = f'google_trends_csvs/{state}_categs.csv'\n",
    "            #statesinfo_df_dict[state].to_csv(output_path, index=False)\n",
    "            #time.sleep(5)\n",
    "        #except IndexError:\n",
    "            #print(f\"problem with {cat_name_list[x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying the function on one state\n",
    "#per_state_info_collector(\"US-AL\")\n",
    "#statesinfo_df_dict['US-AL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting process per category instead of per state\n",
    "#creating list of columns to go into each category's df\n",
    "state_columns_list = ['time'] + abbrev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict to hold all the different category info for all the states\n",
    "cat_info_df_dict = {}\n",
    "for cat in cat_name_list:\n",
    "    cat_info_df_dict[cat] = pd.DataFrame(columns=state_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking length of dict: should be same as len of cat_name_list\n",
    "len(cat_info_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music & Audio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>US-AL</th>\n",
       "      <th>US-AK</th>\n",
       "      <th>US-AZ</th>\n",
       "      <th>US-AR</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-CO</th>\n",
       "      <th>US-CT</th>\n",
       "      <th>US-DE</th>\n",
       "      <th>US-DC</th>\n",
       "      <th>...</th>\n",
       "      <th>US-SD</th>\n",
       "      <th>US-TN</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-UT</th>\n",
       "      <th>US-VT</th>\n",
       "      <th>US-VA</th>\n",
       "      <th>US-WA</th>\n",
       "      <th>US-WV</th>\n",
       "      <th>US-WI</th>\n",
       "      <th>US-WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, US-AL, US-AK, US-AZ, US-AR, US-CA, US-CO, US-CT, US-DE, US-DC, US-FL, US-GA, US-HI, US-ID, US-IL, US-IN, US-IA, US-KS, US-KY, US-LA, US-ME, US-MD, US-MA, US-MI, US-MN, US-MS, US-MO, US-MT, US-NE, US-NV, US-NH, US-NJ, US-NM, US-NY, US-NC, US-ND, US-OH, US-OK, US-OR, US-PA, US-RI, US-SC, US-SD, US-TN, US-TX, US-UT, US-VT, US-VA, US-WA, US-WV, US-WI, US-WY]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing a test df for one category\n",
    "print(cat_name_list[32])\n",
    "cat_info_df_dict[cat_name_list[32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get all data on a category for the states\n",
    "kw_list = '*'\n",
    "\n",
    "def per_cat_info_collector(category_index_num):\n",
    "    for x in range(0, len(abbrev_list)):\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=cat_list[category_index_num], timeframe='2019-01-01 2020-12-20', geo=abbrev_list[x])\n",
    "            cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            cat_interest_df.reset_index(level=0, inplace=True)\n",
    "            #global cat_info_df_dict\n",
    "            cat_info_df_dict[cat_name_list[category_index_num]]['time'] = cat_interest_df['date']\n",
    "            cat_info_df_dict[cat_name_list[category_index_num]][f'{abbrev_list[x]}'] = cat_interest_df['*']\n",
    "            time.sleep(6)\n",
    "        except IndexError:\n",
    "            print(f\"problem with {cat_name_list[category_index_num]}\")\n",
    "    print(cat_info_df_dict[cat_name_list[category_index_num]])\n",
    "    cat_info_df_dict[cat_name_list[category_index_num]]\n",
    "    output_path = f'google_trends_csvs/{cat_name_list[category_index_num]}_states.csv'\n",
    "    cat_info_df_dict[cat_name_list[category_index_num]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(category_index_num):\n",
    "    output_path = f'google_trends_csvs/{cat_name_list[category_index_num]}_states.csv'\n",
    "    #print(output_path)\n",
    "    cat_info_df_dict[cat_name_list[category_index_num]].to_csv(output_path, index=False)\n",
    "    #print(cat_info_df_dict[cat_name_list[category_index_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     80     80     98     96     98     97     93     95     91   \n",
      "1   2019-01-13     80     90     95     97     96     93     87     88     90   \n",
      "2   2019-01-20     75     79     95     94     88     93     88     82     89   \n",
      "3   2019-01-27     74     81     93     91     93     90     85     84     90   \n",
      "4   2019-02-03     76     82     95     92     89     92     87     86     93   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     65     71     85     78     74     78     78     80     47   \n",
      "99  2020-11-29     66     71     83     82     76     80     80     82     52   \n",
      "100 2020-12-06     67     68     90     83     78     84     80     84     54   \n",
      "101 2020-12-13     67     65     80     83     75     80     76     82     50   \n",
      "102 2020-12-20     72     76     88     89     81     85     85     91     49   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     93     83     91     98     93     97     99     91     96     92  \n",
      "1    ...     93     82     92     93     87     96     95     94     92     95  \n",
      "2    ...     91     79     91     92     89     96     93     90     85     89  \n",
      "3    ...     88     75     90     92     88     92     92     89     93     86  \n",
      "4    ...     93     77     91     93     88     90     93     89     93     93  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     81     68     79     79     74     74     82     83     79     79  \n",
      "99   ...     84     70     81     80     72     77     80     87     79     81  \n",
      "100  ...     82     71     83     81     76     80     82     85     80     84  \n",
      "101  ...     81     69     81     81     73     77     82     84     78     77  \n",
      "102  ...     87     74     84     86     87     84     89     86     84     88  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     71     73     75     73     82     66     78     65     79   \n",
      "1   2019-01-13     73     72     78     74     81     68     81     69     76   \n",
      "2   2019-01-20     73     68     77     71     78     66     75     73     72   \n",
      "3   2019-01-27     72     68     77     76     78     67     74     68     86   \n",
      "4   2019-02-03     74     65     76     77     79     70     80     77     84   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     66     58     68     67     68     56     72     72     49   \n",
      "99  2020-11-29     69     58     68     66     72     59     73     64     55   \n",
      "100 2020-12-06     69     57     68     69     70     59     76     71     55   \n",
      "101 2020-12-13     68     55     70     71     69     60     74     69     52   \n",
      "102 2020-12-20     66     53     68     71     69     60     74     69     44   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     62     68     73     64     69     77     70     76     66     63  \n",
      "1    ...     67     69     74     63     73     80     72     76     64     67  \n",
      "2    ...     65     68     71     62     68     77     69     71     61     67  \n",
      "3    ...     65     68     72     61     72     78     70     71     67     63  \n",
      "4    ...     60     70     73     64     74     76     72     76     64     68  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     55     62     63     55     60     64     60     64     55     63  \n",
      "99   ...     61     62     64     56     68     66     58     68     59     62  \n",
      "100  ...     55     63     66     58     60     66     58     70     59     57  \n",
      "101  ...     54     63     66     57     63     65     60     68     59     63  \n",
      "102  ...     60     61     67     57     60     64     61     66     56     57  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     76     79     89     88     95     97     87     78     95   \n",
      "1   2019-01-13     78     81     86     89     89     96     82     78     91   \n",
      "2   2019-01-20     73     85     83     86     90     94     84     75     87   \n",
      "3   2019-01-27     73     87     84     88     89     91     80     78     94   \n",
      "4   2019-02-03     77     77     86     88     88     91     81     76     92   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     64     62     76     76     73     75     75     73     54   \n",
      "99  2020-11-29     71     68     80     82     78     81     80     80     63   \n",
      "100 2020-12-06     68     62     75     82     76     79     78     82     65   \n",
      "101 2020-12-13     70     73     79     79     75     82     75     70     52   \n",
      "102 2020-12-20     74     66     82     82     77     82     85     73     53   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     89     83     87     96    100     98     91     93    100     95  \n",
      "1    ...     91     83     83     96     86     97     90     96     95     95  \n",
      "2    ...     90     78     84     89     82     95     86     86     80     90  \n",
      "3    ...     87     75     83     91     81     92     86     85     76     91  \n",
      "4    ...     90     76     88     91     80     92     79     82     80     83  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     81     67     77     77     69     75     72     75     73     74  \n",
      "99   ...     84     75     79     83     66     79     75     88     77     77  \n",
      "100  ...     77     72     78     82     68     79     72     85     74     84  \n",
      "101  ...     81     73     82     82     70     78     73     81     72     81  \n",
      "102  ...     74     73     82     82     73     81     73     80     73     77  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     73     90     77     82     80     82     85     74     70   \n",
      "1   2019-01-13     82     76     88     87     82     89     84     66     71   \n",
      "2   2019-01-20     82     85     82     81     79     83     75     67     75   \n",
      "3   2019-01-27     79     76     83     88     82     90     79     65     76   \n",
      "4   2019-02-03     84     95     87     88     81     86     76     68     78   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     48     40     57     50     51     54     52     50     30   \n",
      "99  2020-11-29     61     57     64     57     61     63     58     53     37   \n",
      "100 2020-12-06     61     49     67     59     63     68     63     65     37   \n",
      "101 2020-12-13     56     59     66     56     62     67     60     56     41   \n",
      "102 2020-12-20     49     55     56     49     51     55     55     56     32   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     95     84     76     94     89     83     83     85     89     83  \n",
      "1    ...     85     90     84     86     92     88     91     89     87     77  \n",
      "2    ...     88     89     82     86     81     82     87     89     76     80  \n",
      "3    ...     91     84     82     87     88     78     77     80     71     72  \n",
      "4    ...     77     90     84     81     86     78     74     92     82     74  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     55     56     52     64     62     49     57     58     56     55  \n",
      "99   ...     59     66     65     70     57     56     62     77     60     65  \n",
      "100  ...     59     70     68     71     58     62     68     72     64     55  \n",
      "101  ...     49     66     64     69     63     58     68     77     64     56  \n",
      "102  ...     50     53     50     58     56     47     59     64     55     54  \n",
      "\n",
      "[103 rows x 52 columns]\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 429.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b7eedbdd7951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mper_cat_info_collector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-311a564dec0a>\u001b[0m in \u001b[0;36mper_cat_info_collector\u001b[0;34m(category_index_num)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_index_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2019-01-01 2020-12-20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mcat_interest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcat_interest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         widget_dict = self._get_data(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise exceptions.ResponseError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m'The request failed: Google returned a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'response with code {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseError\u001b[0m: The request failed: Google returned a response with code 429."
     ]
    }
   ],
   "source": [
    "for x in range(0, 5):\n",
    "    per_cat_info_collector(x)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business & Industrial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>US-AL</th>\n",
       "      <th>US-AK</th>\n",
       "      <th>US-AZ</th>\n",
       "      <th>US-AR</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-CO</th>\n",
       "      <th>US-CT</th>\n",
       "      <th>US-DE</th>\n",
       "      <th>US-DC</th>\n",
       "      <th>...</th>\n",
       "      <th>US-SD</th>\n",
       "      <th>US-TN</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-UT</th>\n",
       "      <th>US-VT</th>\n",
       "      <th>US-VA</th>\n",
       "      <th>US-WA</th>\n",
       "      <th>US-WV</th>\n",
       "      <th>US-WI</th>\n",
       "      <th>US-WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-11-22</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-12-20</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time  US-AL US-AK US-AZ US-AR US-CA US-CO US-CT US-DE US-DC  ...  \\\n",
       "0   2019-01-06     63   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1   2019-01-13     64   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2   2019-01-20     62   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3   2019-01-27     61   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4   2019-02-03     61   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "..         ...    ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "98  2020-11-22     59   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "99  2020-11-29     68   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "100 2020-12-06     70   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "101 2020-12-13     69   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "102 2020-12-20     74   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "    US-SD US-TN US-TX US-UT US-VT US-VA US-WA US-WV US-WI US-WY  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "98    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "99    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "100   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "101   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "102   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[103 rows x 52 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cat_name_list[4])\n",
    "cat_info_df_dict[cat_name_list[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on above results for x=0-5, it seems the api allows 4 full api calls within a timeframe - attempt to place 4 calls per hour\n",
    "for x in range(4, len(cat_name_list):\n",
    "    if (x % 4 == 0) & x > 4:\n",
    "        time.sleep(60)\n",
    "        per_cat_info_collector(x)\n",
    "    else:\n",
    "        per_cat_info_collector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting to get all data at once: y for index nums of categories, x for state names\n",
    "#kw_list = '*'\n",
    "#for y in range(0, len(cat_name_list)):\n",
    "    #print(cat_name_list[y])\n",
    "    #for x in range(0, len(abbrev_list)):\n",
    "        #try:\n",
    "            #pytrends.build_payload(kw_list, cat=cat_list[y], timeframe='2019-01-01 2020-12-20', geo=abbrev_list[x])\n",
    "            #state_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            #state_interest_df.reset_index(level=0, inplace=True)\n",
    "            #df_dict[cat_name_list[y]]['time'] = state_interest_df['date']\n",
    "            #df_dict[cat_name_list[y]][f'{abbrev_list[x]}'] = state_interest_df['*']\n",
    "        #except IndexError:\n",
    "            #print(f\"problem with {cat_name_list[x]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
