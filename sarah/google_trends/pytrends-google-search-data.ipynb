{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies, and pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "pytrends = TrendReq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty &amp; Fitness</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Books &amp; Literature</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business &amp; Industrial</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category  category_id\n",
       "0   Arts & Entertainment            3\n",
       "1       Autos & Vehicles           47\n",
       "2       Beauty & Fitness           44\n",
       "3     Books & Literature           22\n",
       "4  Business & Industrial           12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the csv of all the categories\n",
    "path = 'categories.csv'\n",
    "categs_df = pd.read_csv(path)\n",
    "categs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Ala.</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Ariz.</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Ark.</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Calif.</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Abbrev Code\n",
       "0     Alabama    Ala.   AL\n",
       "1      Alaska  Alaska   AK\n",
       "2     Arizona   Ariz.   AZ\n",
       "3    Arkansas    Ark.   AR\n",
       "4  California  Calif.   CA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the csv of the state abbreviations\n",
    "states_path = 'statesAbbrev.csv'\n",
    "states_abbrev_df = pd.read_csv(states_path)\n",
    "states_abbrev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a list of the state abbreviations with the country code added in\n",
    "abbrev_list = [f\"US-{x}\" for x in states_abbrev_df['Code']]\n",
    "len(abbrev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US-AL',\n",
       " 'US-AK',\n",
       " 'US-AZ',\n",
       " 'US-AR',\n",
       " 'US-CA',\n",
       " 'US-CO',\n",
       " 'US-CT',\n",
       " 'US-DE',\n",
       " 'US-DC',\n",
       " 'US-FL',\n",
       " 'US-GA',\n",
       " 'US-HI',\n",
       " 'US-ID',\n",
       " 'US-IL',\n",
       " 'US-IN',\n",
       " 'US-IA',\n",
       " 'US-KS',\n",
       " 'US-KY',\n",
       " 'US-LA',\n",
       " 'US-ME',\n",
       " 'US-MD',\n",
       " 'US-MA',\n",
       " 'US-MI',\n",
       " 'US-MN',\n",
       " 'US-MS',\n",
       " 'US-MO',\n",
       " 'US-MT',\n",
       " 'US-NE',\n",
       " 'US-NV',\n",
       " 'US-NH',\n",
       " 'US-NJ',\n",
       " 'US-NM',\n",
       " 'US-NY',\n",
       " 'US-NC',\n",
       " 'US-ND',\n",
       " 'US-OH',\n",
       " 'US-OK',\n",
       " 'US-OR',\n",
       " 'US-PA',\n",
       " 'US-RI',\n",
       " 'US-SC',\n",
       " 'US-SD',\n",
       " 'US-TN',\n",
       " 'US-TX',\n",
       " 'US-UT',\n",
       " 'US-VT',\n",
       " 'US-VA',\n",
       " 'US-WA',\n",
       " 'US-WV',\n",
       " 'US-WI',\n",
       " 'US-WY']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbrev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list for all the category ids\n",
    "cat_list = [x for x in categs_df['category_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list for all the category names\n",
    "cat_name_list = [x for x in categs_df['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of columns to go into each state's df\n",
    "columns_list = ['time'] + cat_name_list\n",
    "#columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict to hold all the different state info on all the categories\n",
    "statesinfo_df_dict = {}\n",
    "for state in abbrev_list:\n",
    "    statesinfo_df_dict[state] = pd.DataFrame(columns=columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of dict: should be same as len of abbrev_list\n",
    "len(statesinfo_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing a test df for one state\n",
    "#print(abbrev_list[27])\n",
    "#statesinfo_df_dict[abbrev_list[27]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kw_list = '*'\n",
    "\n",
    "#def per_state_info_collector(state):\n",
    "    #for x in range(0, len(cat_name_list)):\n",
    "        #try:\n",
    "            #pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2020-12-20', geo=state)\n",
    "            #state_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            #state_interest_df.reset_index(level=0, inplace=True)\n",
    "            #statesinfo_df_dict[state]['time'] = state_interest_df['date']\n",
    "            #statesinfo_df_dict[state][f'{cat_name_list[x]}'] = state_interest_df['*']\n",
    "            #output_path = f'google_trends_csvs/{state}_categs.csv'\n",
    "            #statesinfo_df_dict[state].to_csv(output_path, index=False)\n",
    "            #time.sleep(5)\n",
    "        #except IndexError:\n",
    "            #print(f\"problem with {cat_name_list[x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying the function on one state\n",
    "#per_state_info_collector(\"US-AL\")\n",
    "#statesinfo_df_dict['US-AL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting process per category instead of per state\n",
    "#creating list of columns to go into each category's df\n",
    "state_columns_list = ['time'] + abbrev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict to hold all the different category info for all the states\n",
    "cat_info_df_dict = {}\n",
    "for cat in cat_name_list:\n",
    "    cat_info_df_dict[cat] = pd.DataFrame(columns=state_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of dict: should be same as len of cat_name_list\n",
    "len(cat_info_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music & Audio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>US-AL</th>\n",
       "      <th>US-AK</th>\n",
       "      <th>US-AZ</th>\n",
       "      <th>US-AR</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-CO</th>\n",
       "      <th>US-CT</th>\n",
       "      <th>US-DE</th>\n",
       "      <th>US-DC</th>\n",
       "      <th>...</th>\n",
       "      <th>US-SD</th>\n",
       "      <th>US-TN</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-UT</th>\n",
       "      <th>US-VT</th>\n",
       "      <th>US-VA</th>\n",
       "      <th>US-WA</th>\n",
       "      <th>US-WV</th>\n",
       "      <th>US-WI</th>\n",
       "      <th>US-WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, US-AL, US-AK, US-AZ, US-AR, US-CA, US-CO, US-CT, US-DE, US-DC, US-FL, US-GA, US-HI, US-ID, US-IL, US-IN, US-IA, US-KS, US-KY, US-LA, US-ME, US-MD, US-MA, US-MI, US-MN, US-MS, US-MO, US-MT, US-NE, US-NV, US-NH, US-NJ, US-NM, US-NY, US-NC, US-ND, US-OH, US-OK, US-OR, US-PA, US-RI, US-SC, US-SD, US-TN, US-TX, US-UT, US-VT, US-VA, US-WA, US-WV, US-WI, US-WY]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing a test df for one category\n",
    "print(cat_name_list[32])\n",
    "cat_info_df_dict[cat_name_list[32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get all data on a category for the states\n",
    "kw_list = '*'\n",
    "\n",
    "def per_cat_info_collector(category_index_num):\n",
    "    for x in range(0, len(abbrev_list)):\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=cat_list[category_index_num], timeframe='2019-01-01 2020-12-20', geo=abbrev_list[x])\n",
    "            cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            cat_interest_df.reset_index(level=0, inplace=True)\n",
    "            #global cat_info_df_dict\n",
    "            cat_info_df_dict[cat_name_list[category_index_num]]['time'] = cat_interest_df['date']\n",
    "            cat_info_df_dict[cat_name_list[category_index_num]][f'{abbrev_list[x]}'] = cat_interest_df['*']\n",
    "            time.sleep(6)\n",
    "        except IndexError:\n",
    "            print(f\"problem with {cat_name_list[category_index_num]}\")\n",
    "    print(cat_info_df_dict[cat_name_list[category_index_num]])\n",
    "    cat_info_df_dict[cat_name_list[category_index_num]]\n",
    "    output_path = f'google_trends_csvs/{cat_name_list[category_index_num]}_states.csv'\n",
    "    cat_info_df_dict[cat_name_list[category_index_num]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def save_csv(category_index_num):\n",
    "    #output_path = f'google_trends_csvs/{cat_name_list[category_index_num]}_states.csv'\n",
    "    #print(output_path)\n",
    "    #cat_info_df_dict[cat_name_list[category_index_num]].to_csv(output_path, index=False)\n",
    "    #print(cat_info_df_dict[cat_name_list[category_index_num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_name</th>\n",
       "      <th>cat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports News</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Celebrities &amp; Entertainment News</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Action &amp; Adventure Films</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lottery &amp; Sweepstakes</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Campaigns &amp; Elections</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Online Video</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Law Enforcement</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TV Sci-Fi &amp; Fantasy Shows</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smart Phones</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Infectious Diseases</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Voice &amp; Video Chat</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sony PlayStation</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Health News</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Entertainment Media</td>\n",
       "      <td>1143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cat_name  cat_index\n",
       "0                        Sports News       1077\n",
       "1                            Weather         63\n",
       "2   Celebrities & Entertainment News        184\n",
       "3           Action & Adventure Films       1097\n",
       "4              Lottery & Sweepstakes        364\n",
       "5              Campaigns & Elections        398\n",
       "6                       Online Video        211\n",
       "7                    Law Enforcement        535\n",
       "8          TV Sci-Fi & Fantasy Shows       1112\n",
       "9                       Smart Phones       1071\n",
       "10               Infectious Diseases        632\n",
       "11                Voice & Video Chat        386\n",
       "12                  Sony PlayStation       1044\n",
       "13                       Health News       1253\n",
       "14               Entertainment Media       1143"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'top_cats.csv'\n",
    "top_cats_df = pd.read_csv(path)\n",
    "top_cats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names_list = [x for x in top_cats_df['cat_name']]\n",
    "cat_index_list = [x for x in top_cats_df['cat_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict to hold all the different top category info for all the states\n",
    "top_cat_info_df_dict = {}\n",
    "for cat in cat_names_list:\n",
    "    top_cat_info_df_dict[cat] = pd.DataFrame(columns=state_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>US-AL</th>\n",
       "      <th>US-AK</th>\n",
       "      <th>US-AZ</th>\n",
       "      <th>US-AR</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-CO</th>\n",
       "      <th>US-CT</th>\n",
       "      <th>US-DE</th>\n",
       "      <th>US-DC</th>\n",
       "      <th>...</th>\n",
       "      <th>US-SD</th>\n",
       "      <th>US-TN</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-UT</th>\n",
       "      <th>US-VT</th>\n",
       "      <th>US-VA</th>\n",
       "      <th>US-WA</th>\n",
       "      <th>US-WV</th>\n",
       "      <th>US-WI</th>\n",
       "      <th>US-WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, US-AL, US-AK, US-AZ, US-AR, US-CA, US-CO, US-CT, US-DE, US-DC, US-FL, US-GA, US-HI, US-ID, US-IL, US-IN, US-IA, US-KS, US-KY, US-LA, US-ME, US-MD, US-MA, US-MI, US-MN, US-MS, US-MO, US-MT, US-NE, US-NV, US-NH, US-NJ, US-NM, US-NY, US-NC, US-ND, US-OH, US-OK, US-OR, US-PA, US-RI, US-SC, US-SD, US-TN, US-TX, US-UT, US-VT, US-VA, US-WA, US-WV, US-WI, US-WY]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 52 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test printing a df\n",
    "top_cat_info_df_dict['Sports News']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_cat_info_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = '*'\n",
    "\n",
    "def per_top_cat_info_collector(category_index_num):\n",
    "    for x in range(0, len(abbrev_list)):\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=cat_index_list[category_index_num], timeframe='2019-01-01 2020-12-20', geo=abbrev_list[x])\n",
    "            cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            cat_interest_df.reset_index(level=0, inplace=True)\n",
    "            #global cat_info_df_dict\n",
    "            top_cat_info_df_dict[cat_names_list[category_index_num]]['time'] = cat_interest_df['date']\n",
    "            top_cat_info_df_dict[cat_names_list[category_index_num]][f'{abbrev_list[x]}'] = cat_interest_df['*']\n",
    "            time.sleep(3)\n",
    "        except IndexError:\n",
    "            print(f\"problem with {cat_names_list[category_index_num]}\")\n",
    "    print(top_cat_info_df_dict[cat_names_list[category_index_num]])\n",
    "    top_cat_info_df_dict[cat_names_list[category_index_num]]\n",
    "    output_path = f'google_trends_csvs/top_trends/{cat_names_list[category_index_num]}_states.csv'\n",
    "    top_cat_info_df_dict[cat_names_list[category_index_num]].to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     66     67     76    100     83     66     78     62     60   \n",
      "1   2019-01-13     58     66     70     64     72     63     65     64     87   \n",
      "2   2019-01-20     65     33     57     49     72     73     66     63     46   \n",
      "3   2019-01-27     49     52     65     44     71     50     55     55     62   \n",
      "4   2019-02-03     80     71     59     83     76     75     66     51     54   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     41     35     52     44     53     42     51     46     21   \n",
      "99  2020-11-29     52     29     51     37     51     50     51     61     29   \n",
      "100 2020-12-06     54     47     51     45     53     46     59     52     28   \n",
      "101 2020-12-13     80     36     66     70     63     50     59     42     36   \n",
      "102 2020-12-20     54     13     57     46     60     53     52     40     23   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     96     66     88     62     43     87     70     62     58     68  \n",
      "1    ...     45     64     71     58     55     71     75     60     56     45  \n",
      "2    ...     50     54     74     76     50     75     68     48     54     59  \n",
      "3    ...     29     61     65     66     54     68     58     36     48     30  \n",
      "4    ...     73     84     84     73     33     73     71     74     60     66  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     22     43     53     58     41     51     56     62     41     20  \n",
      "99   ...     44     36     56     62     29     51     60     40     44     26  \n",
      "100  ...     40     52     58     73     15     52     51     32     46     40  \n",
      "101  ...     59     55     82     66     42     61     54     53     54     47  \n",
      "102  ...     54     44     55     54     37     51     49     57     60     51  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     49    100     43     63     69     53     54     63     69   \n",
      "1   2019-01-13     73     72     49     80     89     55    100     89     89   \n",
      "2   2019-01-20     76     76     35     77     41     73     78     66     56   \n",
      "3   2019-01-27    100     82     41     73     78     58     88     86    100   \n",
      "4   2019-02-03     57     77     58     82     91     70     54     44     61   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     49     66     28     56     24     38     43     38     21   \n",
      "99  2020-11-29     58     61     27     60     23     34     55     42     29   \n",
      "100 2020-12-06     43     45     37     53     28     39     44     39     22   \n",
      "101 2020-12-13     53     51     29     82     32     45     99     80     43   \n",
      "102 2020-12-20     57     63     31     55     33     38     57     54     28   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     33     57     58     55     72     88     27     70     35     50  \n",
      "1    ...     57     66     75     63     95    100     23     88     44     54  \n",
      "2    ...     53     77     71     58    100     66     22     73     76     67  \n",
      "3    ...     83    100     77     45     85     92     29    100    100     58  \n",
      "4    ...     69     69     78     81     70     59    100     45     61     73  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     29     45     53     34     38     36     21     35     27     30  \n",
      "99   ...     27     57     60     27     48     46     19     50     22     43  \n",
      "100  ...     27     41     50     37     45     40     20     37     30     42  \n",
      "101  ...     30     53     65     58     67     79     25     76     28     47  \n",
      "102  ...     52     58     50     43     57     53     31     61     35     50  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     68     64     65     67     71     71     59     51     98   \n",
      "1   2019-01-13     69     59     63     66     67     63     60     55     99   \n",
      "2   2019-01-20     59     51     60     62     59     56     52     52     86   \n",
      "3   2019-01-27     67     57     58     63     65     63     55     61     87   \n",
      "4   2019-02-03     66     60     60     68     60     59     55     51     74   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     63     54     63     62     58     60     62     60     38   \n",
      "99  2020-11-29     60     47     57     62     54     57     52     56     47   \n",
      "100 2020-12-06     57     50     56     60     51     52     57     48     51   \n",
      "101 2020-12-13     58     52     55     60     58     58     56     53     45   \n",
      "102 2020-12-20     64     50     61     70     57     58     63     52     40   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     58     68     73     68     62     69     72     69     71     61  \n",
      "1    ...     75     70     69     64     54     69     70     58     66     52  \n",
      "2    ...     50     63     61     58     59     62     64     65     63     54  \n",
      "3    ...     74     67     65     71     52     65     61     57     70     56  \n",
      "4    ...     64     58     64     61     55     57     61     59     60     73  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     88     62     60     55     51     57     61     66     63     55  \n",
      "99   ...     62     64     58     53     60     57     60     62     64     51  \n",
      "100  ...     53     59     56     62     52     54     54     61     66     48  \n",
      "101  ...     75     62     61     64     38     55     60     60     67     79  \n",
      "102  ...     60     67     61     62     49     57     63     66     68     54  \n",
      "\n",
      "[103 rows x 52 columns]\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22%2A%22%2C+%22time%22%3A+%222019-01-01+2020-12-20%22%2C+%22geo%22%3A+%22US-MA%22%7D%5D%2C+%22category%22%3A+1097%2C+%22property%22%3A+%22%22%7D (Caused by NewConnectionError(\"<urllib3.connection.HTTPSConnection object at 0x7fa6c0b31970>: Failed to establish a new connection: [Errno 49] Can't assign requested address\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 49] Can't assign requested address",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7fa6c0b31970>: Failed to establish a new connection: [Errno 49] Can't assign requested address",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    727\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22%2A%22%2C+%22time%22%3A+%222019-01-01+2020-12-20%22%2C+%22geo%22%3A+%22US-MA%22%7D%5D%2C+%22category%22%3A+1097%2C+%22property%22%3A+%22%22%7D (Caused by NewConnectionError(\"<urllib3.connection.HTTPSConnection object at 0x7fa6c0b31970>: Failed to establish a new connection: [Errno 49] Can't assign requested address\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-84af6ba3605a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mper_top_cat_info_collector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-113-4cc559d0bb44>\u001b[0m in \u001b[0;36mper_top_cat_info_collector\u001b[0;34m(category_index_num)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_index_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_index_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2019-01-01 2020-12-20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mcat_interest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcat_interest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         widget_dict = self._get_data(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                               **self.requests_args)  # DO NOT USE retries or backoff_factor here\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             response = s.get(url, timeout=self.timeout, cookies=self.cookies,\n\u001b[0m\u001b[1;32m    138\u001b[0m                              **kwargs, **self.requests_args)  # DO NOT USE retries or backoff_factor here\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# check if the response contains json and throw an exception otherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/~Applications/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='trends.google.com', port=443): Max retries exceeded with url: /trends/api/explore?hl=en-US&tz=360&req=%7B%22comparisonItem%22%3A+%5B%7B%22keyword%22%3A+%22%2A%22%2C+%22time%22%3A+%222019-01-01+2020-12-20%22%2C+%22geo%22%3A+%22US-MA%22%7D%5D%2C+%22category%22%3A+1097%2C+%22property%22%3A+%22%22%7D (Caused by NewConnectionError(\"<urllib3.connection.HTTPSConnection object at 0x7fa6c0b31970>: Failed to establish a new connection: [Errno 49] Can't assign requested address\"))"
     ]
    }
   ],
   "source": [
    "for x in range(0, 4):\n",
    "    per_top_cat_info_collector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     63     50     68     81     68     77     63     51     64   \n",
      "1   2019-01-13     86     74     73     80     71     69     69     57     78   \n",
      "2   2019-01-20     66     71     77     70     66     67     72     80     66   \n",
      "3   2019-01-27     66     67     65     65     62     74     57     67     76   \n",
      "4   2019-02-03     62     62     74     61     62     74     58     58     58   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     71     42     61     57     55     67     61     70     31   \n",
      "99  2020-11-29     72     75     62     72     53     62     58     63     44   \n",
      "100 2020-12-06     61     83     70     63     58     68     60     67     43   \n",
      "101 2020-12-13     68     66     66     64     54     67     55     62     33   \n",
      "102 2020-12-20     77     56     67     74     59     73     68     78     35   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     60     67     73     74     76     75     73     71     77     58  \n",
      "1    ...     72     81     79     72     83     79     84     90     69     87  \n",
      "2    ...     81     77     73     82     64     77     78     93     68     72  \n",
      "3    ...     92     71     69     67     76     66     71     66     66     68  \n",
      "4    ...     80     61     72     72     69     61     74     63     61     74  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     52     63     62     67     77     60     69     83     57     56  \n",
      "99   ...     59     59     64     65     56     54     62     67     55     48  \n",
      "100  ...     73     61     67     62     73     60     64     53     61     64  \n",
      "101  ...     55     65     65     57     67     63     69     76     59     57  \n",
      "102  ...     61     66     68     71     65     65     78     65     68     94  \n",
      "\n",
      "[103 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "for x in range(3, 4):\n",
    "    per_top_cat_info_collector(x)\n",
    "    #time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     56     54     54     60     47     45     60     56     82   \n",
      "1   2019-01-13     60     92     46     40     42     41     47     44     84   \n",
      "2   2019-01-20     59     38     42     39     40     37     49     42     68   \n",
      "3   2019-01-27     45     60     44     55     47     40     59     43     92   \n",
      "4   2019-02-03     54     76     45     59     47     43     58     50     75   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     46     40     40     42     34     37     48     39     54   \n",
      "99  2020-11-29     47     53     39     49     36     36     45     42     64   \n",
      "100 2020-12-06     49     40     43     42     37     40     49     42     64   \n",
      "101 2020-12-13     56     41     50     51     41     45     47     52     59   \n",
      "102 2020-12-20     67     44     56     58     47     51     53     61     72   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     50     59     52     77     54     76     55     38     39     81  \n",
      "1    ...     52     56     51     55     60     77     47     42     39     42  \n",
      "2    ...     36     55     50     52     28     75     44     41     38     45  \n",
      "3    ...     48     55     52     61     55     81     49     44     33     26  \n",
      "4    ...     48     57     53     48     46     76     51     48     44     45  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     63     42     42     49     55     54     32     30     37     27  \n",
      "99   ...     47     48     45     52     41     54     39     35     40     53  \n",
      "100  ...     54     54     46     42     51     56     40     46     43     27  \n",
      "101  ...     44     47     52     60     40     64     52     53     44     27  \n",
      "102  ...     69     53     57     64     96     66     57     57     51     59  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06      0      0      0      0      0      0      0      0      2   \n",
      "1   2019-01-13      0      0      0      0      0      0      0      0      2   \n",
      "2   2019-01-20      0      0      0      0      0      0      0      0      2   \n",
      "3   2019-01-27      0      0      0      0      0      0      0      0      2   \n",
      "4   2019-02-03      0      0      0      0      0      0      0      0      3   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22      1      1      1      1      1      1      1      1      1   \n",
      "99  2020-11-29      1      1      1      1      1      1      1      1      2   \n",
      "100 2020-12-06      1      1      1      1      1      1      1      1      2   \n",
      "101 2020-12-13      1      1      1      1      1      1      1      1      2   \n",
      "102 2020-12-20      0      0      0      0      0      0      0      0      1   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...      0      0      0      0      0      0      0      0      0      0  \n",
      "1    ...      0      0      0      0      0      0      0      0      0      0  \n",
      "2    ...      0      0      0      0      0      0      0      0      0      0  \n",
      "3    ...      0      0      0      0      0      1      0      0      0      0  \n",
      "4    ...      0      0      0      0      0      1      0      0      0      0  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...      1      1      1      1      1      1      1      1      1      1  \n",
      "99   ...      0      1      1      1      1      1      1      1      1      1  \n",
      "100  ...      1      1      1      1      1      1      1      1      1      1  \n",
      "101  ...      1      1      1      1      1      1      1      1      1      1  \n",
      "102  ...      1      0      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     97     81     73     86     87     84     78     74     68   \n",
      "1   2019-01-13     94     83     77     88     88     94     84     83     75   \n",
      "2   2019-01-20     85     92     74     81     89     84     85     63     86   \n",
      "3   2019-01-27     86     89     73     73     85     86     80     80     82   \n",
      "4   2019-02-03     94    100     75     87     84     91     85     75     82   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     67     86     64     62     65     68     63     70     41   \n",
      "99  2020-11-29     70     73     66     66     68     73     66     76     44   \n",
      "100 2020-12-06     69     59     67     65     70     77     65     72     51   \n",
      "101 2020-12-13     76     73     65     65     71     77     63     78     54   \n",
      "102 2020-12-20     75     65     64     64     71     77     70     77     46   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     93     88     75     90     87     91     74    100     92     81  \n",
      "1    ...     94     87     79     75     88     98     75     83     85     75  \n",
      "2    ...     77     83     77     79     87     85     74     80     85     83  \n",
      "3    ...     85     85     79     84     85     85     76     85     85     78  \n",
      "4    ...     72     80     83     74     90     86     78     87     81     67  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     60     66     63     67     74     66     68     78     69     65  \n",
      "99   ...     76     74     70     69     55     73     72     74     68     65  \n",
      "100  ...     69     76     70     66     52     70     72     75     70     71  \n",
      "101  ...     86     70     72     65     69     72     76     78     70     68  \n",
      "102  ...     77     71     63     68     69     69     71     82     69     80  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     60     57     51     60     42     46     41     43     61   \n",
      "1   2019-01-13     67     61     54     70     41     39     39     54     48   \n",
      "2   2019-01-20     67     64     38     65     35     40     41     63     64   \n",
      "3   2019-01-27     64     51     38     65     38     42     41     74     79   \n",
      "4   2019-02-03     70     56     44     94     35     32     44     44     77   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     56     54     38     40     28     32     36     27     17   \n",
      "99  2020-11-29     52     53     44     47     29     30     42     37     37   \n",
      "100 2020-12-06     60     57     36     46     31     36     40     46     30   \n",
      "101 2020-12-13     45     43     46     55     28     37     43     44     24   \n",
      "102 2020-12-20     49     46     33     57     28     28     31     41     27   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     41     66     48     73     66     54     43     59     44     65  \n",
      "1    ...     60     65     48     41     42     47     38     66     50     79  \n",
      "2    ...     62     56     44     39     68     51     35     56     43     77  \n",
      "3    ...     58     57     48     56     57     46     32     52     47     82  \n",
      "4    ...     26     55     49     67     53     50     35     47     52     41  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     64     46     37     39     51     34     28     47     37     94  \n",
      "99   ...     72     42     41     46     47     36     32     59     36     81  \n",
      "100  ...     47     50     39     40     44     44     30     53     40     73  \n",
      "101  ...     60     40     40     47     44     40     28     49     36     49  \n",
      "102  ...     45     45     37     50     41     37     25     43     32     36  \n",
      "\n",
      "[103 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "for x in range(4, 8):\n",
    "    per_top_cat_info_collector(x)\n",
    "    #time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(8, 12):\n",
    "    per_top_cat_info_collector(x)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(12, 15):\n",
    "    per_top_cat_info_collector(x)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     80     80     98     96     98     97     93     95     91   \n",
      "1   2019-01-13     80     90     95     97     96     93     87     88     90   \n",
      "2   2019-01-20     75     79     95     94     88     93     88     82     89   \n",
      "3   2019-01-27     74     81     93     91     93     90     85     84     90   \n",
      "4   2019-02-03     76     82     95     92     89     92     87     86     93   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     65     71     85     78     74     78     78     80     47   \n",
      "99  2020-11-29     66     71     83     82     76     80     80     82     52   \n",
      "100 2020-12-06     67     68     90     83     78     84     80     84     54   \n",
      "101 2020-12-13     67     65     80     83     75     80     76     82     50   \n",
      "102 2020-12-20     72     76     88     89     81     85     85     91     49   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     93     83     91     98     93     97     99     91     96     92  \n",
      "1    ...     93     82     92     93     87     96     95     94     92     95  \n",
      "2    ...     91     79     91     92     89     96     93     90     85     89  \n",
      "3    ...     88     75     90     92     88     92     92     89     93     86  \n",
      "4    ...     93     77     91     93     88     90     93     89     93     93  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     81     68     79     79     74     74     82     83     79     79  \n",
      "99   ...     84     70     81     80     72     77     80     87     79     81  \n",
      "100  ...     82     71     83     81     76     80     82     85     80     84  \n",
      "101  ...     81     69     81     81     73     77     82     84     78     77  \n",
      "102  ...     87     74     84     86     87     84     89     86     84     88  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     71     73     75     73     82     66     78     65     79   \n",
      "1   2019-01-13     73     72     78     74     81     68     81     69     76   \n",
      "2   2019-01-20     73     68     77     71     78     66     75     73     72   \n",
      "3   2019-01-27     72     68     77     76     78     67     74     68     86   \n",
      "4   2019-02-03     74     65     76     77     79     70     80     77     84   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     66     58     68     67     68     56     72     72     49   \n",
      "99  2020-11-29     69     58     68     66     72     59     73     64     55   \n",
      "100 2020-12-06     69     57     68     69     70     59     76     71     55   \n",
      "101 2020-12-13     68     55     70     71     69     60     74     69     52   \n",
      "102 2020-12-20     66     53     68     71     69     60     74     69     44   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     62     68     73     64     69     77     70     76     66     63  \n",
      "1    ...     67     69     74     63     73     80     72     76     64     67  \n",
      "2    ...     65     68     71     62     68     77     69     71     61     67  \n",
      "3    ...     65     68     72     61     72     78     70     71     67     63  \n",
      "4    ...     60     70     73     64     74     76     72     76     64     68  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     55     62     63     55     60     64     60     64     55     63  \n",
      "99   ...     61     62     64     56     68     66     58     68     59     62  \n",
      "100  ...     55     63     66     58     60     66     58     70     59     57  \n",
      "101  ...     54     63     66     57     63     65     60     68     59     63  \n",
      "102  ...     60     61     67     57     60     64     61     66     56     57  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     76     79     89     88     95     97     87     78     95   \n",
      "1   2019-01-13     78     81     86     89     89     96     82     78     91   \n",
      "2   2019-01-20     73     85     83     86     90     94     84     75     87   \n",
      "3   2019-01-27     73     87     84     88     89     91     80     78     94   \n",
      "4   2019-02-03     77     77     86     88     88     91     81     76     92   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     64     62     76     76     73     75     75     73     54   \n",
      "99  2020-11-29     71     68     80     82     78     81     80     80     63   \n",
      "100 2020-12-06     68     62     75     82     76     79     78     82     65   \n",
      "101 2020-12-13     70     73     79     79     75     82     75     70     52   \n",
      "102 2020-12-20     74     66     82     82     77     82     85     73     53   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     89     83     87     96    100     98     91     93    100     95  \n",
      "1    ...     91     83     83     96     86     97     90     96     95     95  \n",
      "2    ...     90     78     84     89     82     95     86     86     80     90  \n",
      "3    ...     87     75     83     91     81     92     86     85     76     91  \n",
      "4    ...     90     76     88     91     80     92     79     82     80     83  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     81     67     77     77     69     75     72     75     73     74  \n",
      "99   ...     84     75     79     83     66     79     75     88     77     77  \n",
      "100  ...     77     72     78     82     68     79     72     85     74     84  \n",
      "101  ...     81     73     82     82     70     78     73     81     72     81  \n",
      "102  ...     74     73     82     82     73     81     73     80     73     77  \n",
      "\n",
      "[103 rows x 52 columns]\n",
      "          time  US-AL  US-AK  US-AZ  US-AR  US-CA  US-CO  US-CT  US-DE  US-DC  \\\n",
      "0   2019-01-06     73     90     77     82     80     82     85     74     70   \n",
      "1   2019-01-13     82     76     88     87     82     89     84     66     71   \n",
      "2   2019-01-20     82     85     82     81     79     83     75     67     75   \n",
      "3   2019-01-27     79     76     83     88     82     90     79     65     76   \n",
      "4   2019-02-03     84     95     87     88     81     86     76     68     78   \n",
      "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "98  2020-11-22     48     40     57     50     51     54     52     50     30   \n",
      "99  2020-11-29     61     57     64     57     61     63     58     53     37   \n",
      "100 2020-12-06     61     49     67     59     63     68     63     65     37   \n",
      "101 2020-12-13     56     59     66     56     62     67     60     56     41   \n",
      "102 2020-12-20     49     55     56     49     51     55     55     56     32   \n",
      "\n",
      "     ...  US-SD  US-TN  US-TX  US-UT  US-VT  US-VA  US-WA  US-WV  US-WI  US-WY  \n",
      "0    ...     95     84     76     94     89     83     83     85     89     83  \n",
      "1    ...     85     90     84     86     92     88     91     89     87     77  \n",
      "2    ...     88     89     82     86     81     82     87     89     76     80  \n",
      "3    ...     91     84     82     87     88     78     77     80     71     72  \n",
      "4    ...     77     90     84     81     86     78     74     92     82     74  \n",
      "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "98   ...     55     56     52     64     62     49     57     58     56     55  \n",
      "99   ...     59     66     65     70     57     56     62     77     60     65  \n",
      "100  ...     59     70     68     71     58     62     68     72     64     55  \n",
      "101  ...     49     66     64     69     63     58     68     77     64     56  \n",
      "102  ...     50     53     50     58     56     47     59     64     55     54  \n",
      "\n",
      "[103 rows x 52 columns]\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 429.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b7eedbdd7951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mper_cat_info_collector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-311a564dec0a>\u001b[0m in \u001b[0;36mper_cat_info_collector\u001b[0;34m(category_index_num)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_index_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2019-01-01 2020-12-20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mcat_interest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcat_interest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         widget_dict = self._get_data(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise exceptions.ResponseError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m'The request failed: Google returned a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'response with code {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseError\u001b[0m: The request failed: Google returned a response with code 429."
     ]
    }
   ],
   "source": [
    "for x in range(0, 5):\n",
    "    per_cat_info_collector(x)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business & Industrial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>US-AL</th>\n",
       "      <th>US-AK</th>\n",
       "      <th>US-AZ</th>\n",
       "      <th>US-AR</th>\n",
       "      <th>US-CA</th>\n",
       "      <th>US-CO</th>\n",
       "      <th>US-CT</th>\n",
       "      <th>US-DE</th>\n",
       "      <th>US-DC</th>\n",
       "      <th>...</th>\n",
       "      <th>US-SD</th>\n",
       "      <th>US-TN</th>\n",
       "      <th>US-TX</th>\n",
       "      <th>US-UT</th>\n",
       "      <th>US-VT</th>\n",
       "      <th>US-VA</th>\n",
       "      <th>US-WA</th>\n",
       "      <th>US-WV</th>\n",
       "      <th>US-WI</th>\n",
       "      <th>US-WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-11-22</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-11-29</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-12-13</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-12-20</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time  US-AL US-AK US-AZ US-AR US-CA US-CO US-CT US-DE US-DC  ...  \\\n",
       "0   2019-01-06     63   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "1   2019-01-13     64   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2   2019-01-20     62   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3   2019-01-27     61   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4   2019-02-03     61   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "..         ...    ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "98  2020-11-22     59   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "99  2020-11-29     68   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "100 2020-12-06     70   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "101 2020-12-13     69   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "102 2020-12-20     74   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "    US-SD US-TN US-TX US-UT US-VT US-VA US-WA US-WV US-WI US-WY  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "98    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "99    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "100   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "101   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "102   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[103 rows x 52 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cat_name_list[4])\n",
    "cat_info_df_dict[cat_name_list[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 429.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e75da949b42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mper_cat_info_collector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mper_cat_info_collector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ecf336a28e1a>\u001b[0m in \u001b[0;36mper_cat_info_collector\u001b[0;34m(category_index_num)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_index_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2019-01-01 2020-12-20'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabbrev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mcat_interest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mcat_interest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         widget_dict = self._get_data(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             raise exceptions.ResponseError(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;34m'The request failed: Google returned a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'response with code {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseError\u001b[0m: The request failed: Google returned a response with code 429."
     ]
    }
   ],
   "source": [
    "#based on above results for x=0-5, it seems the api allows 4 full api calls within a timeframe - attempt to place 4 calls per minute\n",
    "for x in range(4, len(cat_name_list)):\n",
    "    if (x % 4 == 0) & x > 4:\n",
    "        time.sleep(60)\n",
    "        per_cat_info_collector(x)\n",
    "    else:\n",
    "        per_cat_info_collector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Arts &amp; Entertainment</th>\n",
       "      <th>Autos &amp; Vehicles</th>\n",
       "      <th>Beauty &amp; Fitness</th>\n",
       "      <th>Books &amp; Literature</th>\n",
       "      <th>Business &amp; Industrial</th>\n",
       "      <th>Computers &amp; Electronics</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Food &amp; Drink</th>\n",
       "      <th>Games</th>\n",
       "      <th>...</th>\n",
       "      <th>DVD Players &amp; Recorders</th>\n",
       "      <th>Audio Files Formats &amp; Codecs</th>\n",
       "      <th>Fonts</th>\n",
       "      <th>Christmas</th>\n",
       "      <th>Easter</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Babies &amp; Toddlers</th>\n",
       "      <th>Child Care</th>\n",
       "      <th>Youth Camps</th>\n",
       "      <th>Baby Care &amp; Hygiene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, Arts & Entertainment, Autos & Vehicles, Beauty & Fitness, Books & Literature, Business & Industrial, Computers & Electronics, Finance, Food & Drink, Games, Health, Hobbies & Leisure, Home & Garden, Internet & Telecom, Jobs & Education, Law & Government, News, Online Communities, People & Society, Pets & Animals, Real Estate, Reference, Science, Shopping, Sports, Travel, Celebrities & Entertainment News, Comics & Animation, Entertainment Industry, Events & Listings, Fun & Trivia, Humor, Movies, Music & Audio, Offbeat, Online Media, Performing Arts, TV & Video, Visual Art & Design, Automotive Industry, Bicycles & Accessories, Boats & Watercraft, Campers & RVs, Classic Vehicles, Commercial Vehicles, Custom & Performance Vehicles, Hybrid & Alternative Vehicles, Microcars & City Cars, Motorcycles, Off-Road Vehicles, Personal Aircraft, Scooters & Mopeds, Trucks & SUVs, Vehicle Brands, Vehicle Codes & Driving Laws, Vehicle Licensing & Registration, Vehicle Maintenance, Vehicle Parts & Accessories, Vehicle Shopping, Vehicle Shows, Beauty Pageants, Body Art, Cosmetic Procedures, Cosmetology & Beauty Professionals, Face & Body Care, Fashion & Style, Fitness, Hair Care, Spas & Beauty Services, Weight Loss, Biographies & Quotations, Book Retailers, Children's Literature, E-Books, Fan Fiction, Literary Classics, Magazines, Poetry, Writers Resources, Advertising & Marketing, Aerospace & Defense, Agriculture & Forestry, Business Education, Business Finance, Business News, Business Operations, Business Services, Chemicals Industry, Construction & Maintenance, Energy & Utilities, Enterprise Technology, Hospitality Industry, Industrial Materials & Equipment, Manufacturing, Metals & Mining, Pharmaceuticals & Biotech, Printing & Publishing, Professional & Trade Associations, Retail Trade, Small Business, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1133 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_overall_categories_df = pd.DataFrame(columns=columns_list)\n",
    "us_overall_categories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = '*'\n",
    "for x in range(0, 100):\n",
    "    if x == 0:\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2019-01-01', geo='US')\n",
    "            us_cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            us_cat_interest_df.reset_index(level=0, inplace=True)\n",
    "            us_overall_categories_df['time'] = us_cat_interest_df['date']\n",
    "            us_overall_categories_df[f'{cat_name_list[x]}'] = us_cat_interest_df['*']\n",
    "            time.sleep(6)\n",
    "        except IndexError:\n",
    "            print(f\"problem with {cat_name_list[category_index_num]}\")\n",
    "    else:\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2019-01-02', geo='US')\n",
    "            us_cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "            us_cat_interest_df.reset_index(level=0, inplace=True)\n",
    "            us_overall_categories_df[f'{cat_name_list[x]}'] = us_cat_interest_df['*']\n",
    "            time.sleep(6)\n",
    "        except IndexError:\n",
    "            print(f\"problem with {cat_name_list[category_index_num]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enterprise Technology</th>\n",
       "      <th>Hospitality Industry</th>\n",
       "      <th>Industrial Materials &amp; Equipment</th>\n",
       "      <th>Manufacturing</th>\n",
       "      <th>Metals &amp; Mining</th>\n",
       "      <th>Pharmaceuticals &amp; Biotech</th>\n",
       "      <th>Printing &amp; Publishing</th>\n",
       "      <th>Professional &amp; Trade Associations</th>\n",
       "      <th>Retail Trade</th>\n",
       "      <th>Small Business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>68</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Enterprise Technology  Hospitality Industry  \\\n",
       "0                     63                   100   \n",
       "1                    100                    65   \n",
       "\n",
       "   Industrial Materials & Equipment  Manufacturing  Metals & Mining  \\\n",
       "0                                68             55               74   \n",
       "1                               100            100              100   \n",
       "\n",
       "   Pharmaceuticals & Biotech  Printing & Publishing  \\\n",
       "0                         39                     82   \n",
       "1                        100                    100   \n",
       "\n",
       "   Professional & Trade Associations  Retail Trade  Small Business  \n",
       "0                                 62           100              79  \n",
       "1                                100            98             100  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_overall_categories_df.iloc[:, 90:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_list = '*'\n",
    "def cat_cycle(y):\n",
    "    for x in range(y, y+100):\n",
    "        if x == 0:\n",
    "            try:\n",
    "                pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2019-01-01', geo='US')\n",
    "                us_cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "                us_cat_interest_df.reset_index(level=0, inplace=True)\n",
    "                us_overall_categories_df['time'] = us_cat_interest_df['date']\n",
    "                us_overall_categories_df[f'{cat_name_list[x]}'] = us_cat_interest_df['*']\n",
    "                time.sleep(6)\n",
    "            except IndexError:\n",
    "                print(f\"problem with {cat_name_list[category_index_num]}\")\n",
    "        else:\n",
    "            try:\n",
    "                pytrends.build_payload(kw_list, cat=cat_list[x], timeframe='2019-01-01 2019-01-01', geo='US')\n",
    "                us_cat_interest_df = pd.DataFrame(pytrends.interest_over_time())\n",
    "                us_cat_interest_df.reset_index(level=0, inplace=True)\n",
    "                us_overall_categories_df[f'{cat_name_list[x]}'] = us_cat_interest_df['*']\n",
    "                time.sleep(6)\n",
    "            except IndexError:\n",
    "                print(f\"problem with {cat_name_list[category_index_num]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = np.arange(0, 1200, 100)\n",
    "for num in num_list:\n",
    "    cat_cycle(num)\n",
    "    time.sleep(3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Arts &amp; Entertainment</th>\n",
       "      <th>Autos &amp; Vehicles</th>\n",
       "      <th>Beauty &amp; Fitness</th>\n",
       "      <th>Books &amp; Literature</th>\n",
       "      <th>Business &amp; Industrial</th>\n",
       "      <th>Computers &amp; Electronics</th>\n",
       "      <th>Finance</th>\n",
       "      <th>Food &amp; Drink</th>\n",
       "      <th>Games</th>\n",
       "      <th>...</th>\n",
       "      <th>DVD Players &amp; Recorders</th>\n",
       "      <th>Audio Files Formats &amp; Codecs</th>\n",
       "      <th>Fonts</th>\n",
       "      <th>Christmas</th>\n",
       "      <th>Easter</th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Babies &amp; Toddlers</th>\n",
       "      <th>Child Care</th>\n",
       "      <th>Youth Camps</th>\n",
       "      <th>Baby Care &amp; Hygiene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>94</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>69</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>93</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>92</td>\n",
       "      <td>76</td>\n",
       "      <td>93</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>91</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  Arts & Entertainment  Autos & Vehicles  Beauty & Fitness  \\\n",
       "0 2019-01-06                    94                71                94   \n",
       "1 2019-01-13                    92                75                92   \n",
       "2 2019-01-20                    89                71                91   \n",
       "3 2019-01-27                    89                73                91   \n",
       "4 2019-02-03                    89                76                93   \n",
       "5 2019-02-10                    95                72                90   \n",
       "6 2019-02-17                    92                76                93   \n",
       "7 2019-02-24                   100                76                91   \n",
       "8 2019-03-03                    94                78                91   \n",
       "9 2019-03-10                    89                76                90   \n",
       "\n",
       "   Books & Literature  Business & Industrial  Computers & Electronics  \\\n",
       "0                  78                     69                       88   \n",
       "1                  85                     70                       94   \n",
       "2                  78                     69                       89   \n",
       "3                  77                     70                       90   \n",
       "4                  81                     68                       90   \n",
       "5                  83                     70                       90   \n",
       "6                  78                     66                       87   \n",
       "7                  85                     74                       88   \n",
       "8                  85                     69                       91   \n",
       "9                  77                     67                       86   \n",
       "\n",
       "   Finance  Food & Drink  Games  ...  DVD Players & Recorders  \\\n",
       "0       68            74     83  ...                      NaN   \n",
       "1       70            76     83  ...                      NaN   \n",
       "2       69            77     82  ...                      NaN   \n",
       "3       78            74     85  ...                      NaN   \n",
       "4       83            76     79  ...                      NaN   \n",
       "5       81            78     80  ...                      NaN   \n",
       "6       85            74     79  ...                      NaN   \n",
       "7       80            74     79  ...                      NaN   \n",
       "8       76            75     79  ...                      NaN   \n",
       "9       72            75     80  ...                      NaN   \n",
       "\n",
       "   Audio Files Formats & Codecs  Fonts  Christmas  Easter  Adoption  \\\n",
       "0                           NaN    NaN        NaN     NaN       NaN   \n",
       "1                           NaN    NaN        NaN     NaN       NaN   \n",
       "2                           NaN    NaN        NaN     NaN       NaN   \n",
       "3                           NaN    NaN        NaN     NaN       NaN   \n",
       "4                           NaN    NaN        NaN     NaN       NaN   \n",
       "5                           NaN    NaN        NaN     NaN       NaN   \n",
       "6                           NaN    NaN        NaN     NaN       NaN   \n",
       "7                           NaN    NaN        NaN     NaN       NaN   \n",
       "8                           NaN    NaN        NaN     NaN       NaN   \n",
       "9                           NaN    NaN        NaN     NaN       NaN   \n",
       "\n",
       "   Babies & Toddlers  Child Care  Youth Camps  Baby Care & Hygiene  \n",
       "0                NaN         NaN          NaN                  NaN  \n",
       "1                NaN         NaN          NaN                  NaN  \n",
       "2                NaN         NaN          NaN                  NaN  \n",
       "3                NaN         NaN          NaN                  NaN  \n",
       "4                NaN         NaN          NaN                  NaN  \n",
       "5                NaN         NaN          NaN                  NaN  \n",
       "6                NaN         NaN          NaN                  NaN  \n",
       "7                NaN         NaN          NaN                  NaN  \n",
       "8                NaN         NaN          NaN                  NaN  \n",
       "9                NaN         NaN          NaN                  NaN  \n",
       "\n",
       "[10 rows x 1133 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_overall_categories_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
