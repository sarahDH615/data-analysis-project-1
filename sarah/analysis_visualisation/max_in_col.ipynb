{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Abbrev</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>R.I.</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>S.C.</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>S.D.</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Tenn.</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Tex.</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>Vt.</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Va.</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Wash.</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>W.Va.</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wis.</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Wyo.</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State Abbrev Code\n",
       "39    Rhode Island   R.I.   RI\n",
       "40  South Carolina   S.C.   SC\n",
       "41    South Dakota   S.D.   SD\n",
       "42       Tennessee  Tenn.   TN\n",
       "43           Texas   Tex.   TX\n",
       "44            Utah   Utah   UT\n",
       "45         Vermont    Vt.   VT\n",
       "46        Virginia    Va.   VA\n",
       "47      Washington  Wash.   WA\n",
       "48   West Virginia  W.Va.   WV\n",
       "49       Wisconsin   Wis.   WI\n",
       "50         Wyoming   Wyo.   WY"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in the state abbreviations\n",
    "path = '../google_trends/statesAbbrev.csv'\n",
    "statesAbbrev_df = pd.read_csv(path)\n",
    "statesAbbrev_df.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list for state codes\n",
    "state_codes = [x for x in statesAbbrev_df['Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df dict to hold the state dfs, reading in the dfs\n",
    "states_df_dict = {}\n",
    "for x in range(40, 51):\n",
    "    path = f'../google_trends/google_trends_csvs/state_csvs/US-{state_codes[x]}_cat_data.csv'\n",
    "    states_df_dict[f'{state_codes[x]}_data_df'] = [pd.read_csv(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SC_data_df', 'SD_data_df', 'TN_data_df', 'TX_data_df', 'UT_data_df', 'VT_data_df', 'VA_data_df', 'WA_data_df', 'WV_data_df', 'WI_data_df', 'WY_data_df'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the keys (ie df names)\n",
    "states_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>autos</th>\n",
       "      <th>beauty_fitness</th>\n",
       "      <th>books_lit</th>\n",
       "      <th>action_adventure</th>\n",
       "      <th>campaigns_elections</th>\n",
       "      <th>celebs</th>\n",
       "      <th>discrimination</th>\n",
       "      <th>entertainment_media</th>\n",
       "      <th>...</th>\n",
       "      <th>mobiles</th>\n",
       "      <th>online_vids</th>\n",
       "      <th>scifi_fantasy</th>\n",
       "      <th>sport_news</th>\n",
       "      <th>tv_shows</th>\n",
       "      <th>voice_vid_chat</th>\n",
       "      <th>weather</th>\n",
       "      <th>covid_cases</th>\n",
       "      <th>stay_at_home</th>\n",
       "      <th>mass_gathering_ban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>92</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>87</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>87</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>89</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>94</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>83</td>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>81</td>\n",
       "      <td>42</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>95</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>92</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>95</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>91</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>83</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>94</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>93</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "      <td>91</td>\n",
       "      <td>52</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>84</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  arts_entertainment  autos  beauty_fitness  books_lit  \\\n",
       "0  2019-01-06                  96     78              70         87   \n",
       "1  2019-01-13                  95     76              73         87   \n",
       "2  2019-01-20                  88     80              71         81   \n",
       "3  2019-01-27                  93     76              70         83   \n",
       "4  2019-02-03                  92     78              72         88   \n",
       "5  2019-02-10                  95     80              68         92   \n",
       "6  2019-02-17                  95     82              76         90   \n",
       "7  2019-02-24                 100     84              73         94   \n",
       "8  2019-03-03                  97     82              72         93   \n",
       "9  2019-03-10                  93     83              68         86   \n",
       "\n",
       "   action_adventure  campaigns_elections  celebs  discrimination  \\\n",
       "0                68                    0      65              22   \n",
       "1                74                    0      66              10   \n",
       "2                69                    0      61              18   \n",
       "3                71                    0      66              17   \n",
       "4                65                    0      61              26   \n",
       "5                58                    0      63              20   \n",
       "6                66                    0      78              23   \n",
       "7                64                    0      69              25   \n",
       "8                63                    0      59              46   \n",
       "9                55                    0      68              22   \n",
       "\n",
       "   entertainment_media  ...  mobiles  online_vids  scifi_fantasy  sport_news  \\\n",
       "0                   68  ...       60           92             66          80   \n",
       "1                   83  ...       61           87             54          48   \n",
       "2                   73  ...       62           83             55          54   \n",
       "3                   80  ...       61           94             43          44   \n",
       "4                   60  ...       61           81             42          73   \n",
       "5                   72  ...       64           91             51          47   \n",
       "6                   67  ...       67           91             40          40   \n",
       "7                   68  ...       64           87             55          45   \n",
       "8                   75  ...       70           89             51          39   \n",
       "9                   66  ...       64           84             46          63   \n",
       "\n",
       "   tv_shows  voice_vid_chat  weather  covid_cases  stay_at_home  \\\n",
       "0        91              37       59          NaN         False   \n",
       "1        79              35       68          NaN         False   \n",
       "2        89              41       68          NaN         False   \n",
       "3        83              48       69          NaN         False   \n",
       "4        89              58       57          NaN         False   \n",
       "5        78              43       70          NaN         False   \n",
       "6        83              53       80          NaN         False   \n",
       "7        86              70       74          NaN         False   \n",
       "8        91              52       76          NaN         False   \n",
       "9        84              55       58          NaN         False   \n",
       "\n",
       "   mass_gathering_ban  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "5               False  \n",
       "6               False  \n",
       "7               False  \n",
       "8               False  \n",
       "9               False  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test printing a df\n",
    "print(state_codes[40])\n",
    "states_df_dict[f'{state_codes[40]}_data_df'][0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(states_df_dict[f'{state_codes[40]}_data_df'][0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_for_max = [x for x in col_names if x not in ['time', 'covid_cases', 'stay_at_home', 'mass_gathering_ban']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_list = list(states_df_dict[f'{state_codes[40]}_data_df'][0]['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-01-06',\n",
       " '2019-01-13',\n",
       " '2019-01-20',\n",
       " '2019-01-27',\n",
       " '2019-02-03',\n",
       " '2019-02-10',\n",
       " '2019-02-17',\n",
       " '2019-02-24',\n",
       " '2019-03-03',\n",
       " '2019-03-10',\n",
       " '2019-03-17',\n",
       " '2019-03-24',\n",
       " '2019-03-31',\n",
       " '2019-04-07',\n",
       " '2019-04-14',\n",
       " '2019-04-21',\n",
       " '2019-04-28',\n",
       " '2019-05-05',\n",
       " '2019-05-12',\n",
       " '2019-05-19',\n",
       " '2019-05-26',\n",
       " '2019-06-02',\n",
       " '2019-06-09',\n",
       " '2019-06-16',\n",
       " '2019-06-23',\n",
       " '2019-06-30',\n",
       " '2019-07-07',\n",
       " '2019-07-14',\n",
       " '2019-07-21',\n",
       " '2019-07-28',\n",
       " '2019-08-04',\n",
       " '2019-08-11',\n",
       " '2019-08-18',\n",
       " '2019-08-25',\n",
       " '2019-09-01',\n",
       " '2019-09-08',\n",
       " '2019-09-15',\n",
       " '2019-09-22',\n",
       " '2019-09-29',\n",
       " '2019-10-06',\n",
       " '2019-10-13',\n",
       " '2019-10-20',\n",
       " '2019-10-27',\n",
       " '2019-11-03',\n",
       " '2019-11-10',\n",
       " '2019-11-17',\n",
       " '2019-11-24',\n",
       " '2019-12-01',\n",
       " '2019-12-08',\n",
       " '2019-12-15',\n",
       " '2019-12-22',\n",
       " '2019-12-29',\n",
       " '2020-01-05',\n",
       " '2020-01-12',\n",
       " '2020-01-19',\n",
       " '2020-01-26',\n",
       " '2020-02-02',\n",
       " '2020-02-09',\n",
       " '2020-02-16',\n",
       " '2020-02-23',\n",
       " '2020-03-01',\n",
       " '2020-03-08',\n",
       " '2020-03-15',\n",
       " '2020-03-22',\n",
       " '2020-03-29',\n",
       " '2020-04-05',\n",
       " '2020-04-12',\n",
       " '2020-04-19',\n",
       " '2020-04-26',\n",
       " '2020-05-03',\n",
       " '2020-05-10',\n",
       " '2020-05-17',\n",
       " '2020-05-24',\n",
       " '2020-05-31',\n",
       " '2020-06-07',\n",
       " '2020-06-14',\n",
       " '2020-06-21',\n",
       " '2020-06-28',\n",
       " '2020-07-05',\n",
       " '2020-07-12',\n",
       " '2020-07-19',\n",
       " '2020-07-26',\n",
       " '2020-08-02',\n",
       " '2020-08-09',\n",
       " '2020-08-16',\n",
       " '2020-08-23',\n",
       " '2020-08-30',\n",
       " '2020-09-06',\n",
       " '2020-09-13',\n",
       " '2020-09-20',\n",
       " '2020-09-27',\n",
       " '2020-10-04',\n",
       " '2020-10-11',\n",
       " '2020-10-18',\n",
       " '2020-10-25',\n",
       " '2020-11-01',\n",
       " '2020-11-08',\n",
       " '2020-11-15',\n",
       " '2020-11-22',\n",
       " '2020-11-29',\n",
       " '2020-12-06',\n",
       " '2020-12-13',\n",
       " '2020-12-20']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_col_dict = {}\n",
    "for x in range(0, len(col_names_for_max)):\n",
    "    for y in range(0, len(states_df_dict[f'{state_codes[40]}_data_df'][0])):\n",
    "        if states_df_dict[f'{state_codes[40]}_data_df'][0].iloc[y, x+1] == states_df_dict[f'{state_codes[40]}_data_df'][0][col_names_for_max[x]].max():\n",
    "            max_per_col_dict[f'{col_names_for_max[x]}'] = (times_list[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_per_col_df = pd.DataFrame({'max_date': list(max_per_col_dict.values()), 'cat': list(max_per_col_dict.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df_dict[f'{state_codes[40]}_data_df'].append(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_date</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>arts_entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>beauty_fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>books_lit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>action_adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>campaigns_elections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>celebs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>discrimination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>entertainment_media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>games_systems_consoles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>health_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>infectious_diseases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>law_enf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>lottos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>online_vids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-11-10</td>\n",
       "      <td>scifi_fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>sport_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>tv_shows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>voice_vid_chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_date                     cat\n",
       "0   2019-02-24      arts_entertainment\n",
       "1   2019-09-08                   autos\n",
       "2   2020-05-17          beauty_fitness\n",
       "3   2019-04-28               books_lit\n",
       "4   2020-10-25        action_adventure\n",
       "5   2020-11-01     campaigns_elections\n",
       "6   2020-11-01                  celebs\n",
       "7   2020-06-21          discrimination\n",
       "8   2020-03-29     entertainment_media\n",
       "9   2020-11-08  games_systems_consoles\n",
       "10  2020-04-19             health_news\n",
       "11  2020-03-15     infectious_diseases\n",
       "12  2020-05-31                 law_enf\n",
       "13  2019-03-24                  lottos\n",
       "14  2019-09-08                 mobiles\n",
       "15  2019-09-15             online_vids\n",
       "16  2019-11-10           scifi_fantasy\n",
       "17  2019-12-15              sport_news\n",
       "18  2019-09-15                tv_shows\n",
       "19  2019-05-19          voice_vid_chat\n",
       "20  2020-02-16                 weather"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_df_dict[f'{state_codes[40]}_data_df'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_col_dates(ind_num):\n",
    "    max_per_col_dict = {}\n",
    "    for x in range(0, len(col_names_for_max)):\n",
    "        for y in range(0, len(states_df_dict[f'{state_codes[ind_num]}_data_df'][0])):\n",
    "            # x+1 here because column 0 in the list is a cat, but col 0 on the df is 'time', so moving over index by one to get correct col\n",
    "            if states_df_dict[f'{state_codes[ind_num]}_data_df'][0].iloc[y, x+1] == states_df_dict[f'{state_codes[ind_num]}_data_df'][0][col_names_for_max[x]].max():\n",
    "                max_per_col_dict[f'{col_names_for_max[x]}'] = (times_list[y])\n",
    "    max_per_col_df = pd.DataFrame({'max_date': max_per_col_dict.values(), 'cat': max_per_col_dict.keys()})\n",
    "    states_df_dict[f'{state_codes[ind_num]}_data_df'].append(max_per_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      max_date                     cat\n",
      "0   2019-02-24      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-05-17          beauty_fitness\n",
      "3   2019-04-28               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-29     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2019-09-15             online_vids\n",
      "16  2019-11-10           scifi_fantasy\n",
      "17  2019-12-15              sport_news\n",
      "18  2019-09-15                tv_shows\n",
      "19  2019-05-19          voice_vid_chat\n",
      "20  2020-02-16                 weather\n",
      "      max_date                     cat\n",
      "0   2020-04-12      arts_entertainment\n",
      "1   2019-08-04                   autos\n",
      "2   2019-12-29          beauty_fitness\n",
      "3   2019-05-05               books_lit\n",
      "4   2019-01-27        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-08                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2019-12-29     entertainment_media\n",
      "9   2020-04-12  games_systems_consoles\n",
      "10  2020-03-15             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2019-03-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2019-01-13             online_vids\n",
      "16  2020-03-22           scifi_fantasy\n",
      "17  2019-04-28              sport_news\n",
      "18  2019-09-15                tv_shows\n",
      "19  2019-12-15          voice_vid_chat\n",
      "20  2019-04-07                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-22      arts_entertainment\n",
      "1   2019-09-01                   autos\n",
      "2   2019-12-22          beauty_fitness\n",
      "3   2019-04-14               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2019-12-22     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-06-14                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2019-08-25             online_vids\n",
      "16  2019-12-22           scifi_fantasy\n",
      "17  2019-12-15              sport_news\n",
      "18  2019-03-03                tv_shows\n",
      "19  2019-12-15          voice_vid_chat\n",
      "20  2019-01-27                 weather\n",
      "      max_date                     cat\n",
      "0   2019-02-24      arts_entertainment\n",
      "1   2019-09-15                   autos\n",
      "2   2020-05-17          beauty_fitness\n",
      "3   2019-04-28               books_lit\n",
      "4   2019-10-06        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-29     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-03-29             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-09-13             online_vids\n",
      "16  2019-12-22           scifi_fantasy\n",
      "17  2019-10-27              sport_news\n",
      "18  2019-09-15                tv_shows\n",
      "19  2020-03-15          voice_vid_chat\n",
      "20  2019-11-10                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-05-03          beauty_fitness\n",
      "3   2019-04-14               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-05-31          discrimination\n",
      "8   2019-12-29     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-03-22             online_vids\n",
      "16  2020-12-20           scifi_fantasy\n",
      "17  2019-10-20              sport_news\n",
      "18  2019-03-03                tv_shows\n",
      "19  2020-03-22          voice_vid_chat\n",
      "20  2019-11-24                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-01                   autos\n",
      "2   2019-01-06          beauty_fitness\n",
      "3   2019-04-28               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-10-04                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-22     entertainment_media\n",
      "9   2020-04-12  games_systems_consoles\n",
      "10  2020-07-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-06-07                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-12-29                 mobiles\n",
      "15  2020-09-13             online_vids\n",
      "16  2020-12-20           scifi_fantasy\n",
      "17  2019-05-05              sport_news\n",
      "18  2020-04-12                tv_shows\n",
      "19  2020-03-15          voice_vid_chat\n",
      "20  2019-01-20                 weather\n",
      "      max_date                     cat\n",
      "0   2019-03-03      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-06-07          beauty_fitness\n",
      "3   2019-04-28               books_lit\n",
      "4   2019-10-06        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-22     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-03-29             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-09-13             online_vids\n",
      "16  2019-11-10           scifi_fantasy\n",
      "17  2019-10-27              sport_news\n",
      "18  2019-09-15                tv_shows\n",
      "19  2020-03-15          voice_vid_chat\n",
      "20  2019-01-13                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-06-07          beauty_fitness\n",
      "3   2019-04-14               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-05-31          discrimination\n",
      "8   2020-04-19     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-26             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-09-13             online_vids\n",
      "16  2019-12-22           scifi_fantasy\n",
      "17  2019-03-10              sport_news\n",
      "18  2019-09-15                tv_shows\n",
      "19  2020-03-22          voice_vid_chat\n",
      "20  2019-02-03                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2020-05-03          beauty_fitness\n",
      "3   2020-03-01               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2019-12-22     entertainment_media\n",
      "9   2020-11-22  games_systems_consoles\n",
      "10  2020-04-12             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-12-01                 mobiles\n",
      "15  2020-03-22             online_vids\n",
      "16  2019-12-22           scifi_fantasy\n",
      "17  2019-03-10              sport_news\n",
      "18  2020-11-08                tv_shows\n",
      "19  2019-09-29          voice_vid_chat\n",
      "20  2019-01-27                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-08                   autos\n",
      "2   2019-01-06          beauty_fitness\n",
      "3   2019-05-05               books_lit\n",
      "4   2020-10-25        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-01                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-22     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-04-19             health_news\n",
      "11  2020-03-15     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-03-24                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2020-09-13             online_vids\n",
      "16  2019-12-29           scifi_fantasy\n",
      "17  2019-09-15              sport_news\n",
      "18  2020-01-05                tv_shows\n",
      "19  2020-03-15          voice_vid_chat\n",
      "20  2019-01-27                 weather\n",
      "      max_date                     cat\n",
      "0   2019-12-29      arts_entertainment\n",
      "1   2019-09-01                   autos\n",
      "2   2020-01-19          beauty_fitness\n",
      "3   2019-04-14               books_lit\n",
      "4   2019-10-06        action_adventure\n",
      "5   2020-11-01     campaigns_elections\n",
      "6   2020-11-08                  celebs\n",
      "7   2020-06-21          discrimination\n",
      "8   2020-03-22     entertainment_media\n",
      "9   2020-11-08  games_systems_consoles\n",
      "10  2020-03-08             health_news\n",
      "11  2020-03-22     infectious_diseases\n",
      "12  2020-05-31                 law_enf\n",
      "13  2019-04-28                  lottos\n",
      "14  2019-09-08                 mobiles\n",
      "15  2019-11-10             online_vids\n",
      "16  2019-12-22           scifi_fantasy\n",
      "17  2019-04-14              sport_news\n",
      "18  2019-04-28                tv_shows\n",
      "19  2020-03-15          voice_vid_chat\n",
      "20  2019-11-24                 weather\n"
     ]
    }
   ],
   "source": [
    "for x in range(40, 51):\n",
    "    get_max_col_dates(x)\n",
    "    print(states_df_dict[f'{state_codes[x]}_data_df'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_merge_list = [states_df_dict[f'{state_codes[x]}_data_df'][1] for x in range(40,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(for_merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(40, 51):\n",
    "    states_df_dict[f'{state_codes[x]}_data_df'][1].rename(columns={'max_date': f'{state_codes[x]}_max_date'}, \n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SC_max_date</th>\n",
       "      <th>cat</th>\n",
       "      <th>SD_max_date</th>\n",
       "      <th>TN_max_date</th>\n",
       "      <th>TX_max_date</th>\n",
       "      <th>UT_max_date</th>\n",
       "      <th>VT_max_date</th>\n",
       "      <th>VA_max_date</th>\n",
       "      <th>WA_max_date</th>\n",
       "      <th>WV_max_date</th>\n",
       "      <th>WI_max_date</th>\n",
       "      <th>WY_max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>autos</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>beauty_fitness</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2020-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>books_lit</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2019-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>action_adventure</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SC_max_date                 cat SD_max_date TN_max_date TX_max_date  \\\n",
       "0  2019-02-24  arts_entertainment  2020-04-12  2019-12-22  2019-02-24   \n",
       "1  2019-09-08               autos  2019-08-04  2019-09-01  2019-09-15   \n",
       "2  2020-05-17      beauty_fitness  2019-12-29  2019-12-22  2020-05-17   \n",
       "3  2019-04-28           books_lit  2019-05-05  2019-04-14  2019-04-28   \n",
       "4  2020-10-25    action_adventure  2019-01-27  2020-10-25  2019-10-06   \n",
       "\n",
       "  UT_max_date VT_max_date VA_max_date WA_max_date WV_max_date WI_max_date  \\\n",
       "0  2019-12-29  2019-12-29  2019-03-03  2019-12-29  2019-12-29  2019-12-29   \n",
       "1  2019-09-08  2019-09-01  2019-09-08  2019-09-08  2019-09-08  2019-09-08   \n",
       "2  2020-05-03  2019-01-06  2020-06-07  2020-06-07  2020-05-03  2019-01-06   \n",
       "3  2019-04-14  2019-04-28  2019-04-28  2019-04-14  2020-03-01  2019-05-05   \n",
       "4  2020-10-25  2020-10-25  2019-10-06  2020-10-25  2020-10-25  2020-10-25   \n",
       "\n",
       "  WY_max_date  \n",
       "0  2019-12-29  \n",
       "1  2019-09-01  \n",
       "2  2020-01-19  \n",
       "3  2019-04-14  \n",
       "4  2019-10-06  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df = reduce(lambda left,right: pd.merge(left,right,on=['cat'],\n",
    "                                            how='outer'), for_merge_list)\n",
    "combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(combo_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cat',\n",
    " 'SC_max_date',\n",
    " 'SD_max_date',\n",
    " 'TN_max_date',\n",
    " 'TX_max_date',\n",
    " 'UT_max_date',\n",
    " 'VT_max_date',\n",
    " 'VA_max_date',\n",
    " 'WA_max_date',\n",
    " 'WV_max_date',\n",
    " 'WI_max_date',\n",
    " 'WY_max_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>SC_max_date</th>\n",
       "      <th>SD_max_date</th>\n",
       "      <th>TN_max_date</th>\n",
       "      <th>TX_max_date</th>\n",
       "      <th>UT_max_date</th>\n",
       "      <th>VT_max_date</th>\n",
       "      <th>VA_max_date</th>\n",
       "      <th>WA_max_date</th>\n",
       "      <th>WV_max_date</th>\n",
       "      <th>WI_max_date</th>\n",
       "      <th>WY_max_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arts_entertainment</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autos</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>2019-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beauty_fitness</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2020-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books_lit</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2019-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>action_adventure</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>2019-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cat SC_max_date SD_max_date TN_max_date TX_max_date  \\\n",
       "0  arts_entertainment  2019-02-24  2020-04-12  2019-12-22  2019-02-24   \n",
       "1               autos  2019-09-08  2019-08-04  2019-09-01  2019-09-15   \n",
       "2      beauty_fitness  2020-05-17  2019-12-29  2019-12-22  2020-05-17   \n",
       "3           books_lit  2019-04-28  2019-05-05  2019-04-14  2019-04-28   \n",
       "4    action_adventure  2020-10-25  2019-01-27  2020-10-25  2019-10-06   \n",
       "\n",
       "  UT_max_date VT_max_date VA_max_date WA_max_date WV_max_date WI_max_date  \\\n",
       "0  2019-12-29  2019-12-29  2019-03-03  2019-12-29  2019-12-29  2019-12-29   \n",
       "1  2019-09-08  2019-09-01  2019-09-08  2019-09-08  2019-09-08  2019-09-08   \n",
       "2  2020-05-03  2019-01-06  2020-06-07  2020-06-07  2020-05-03  2019-01-06   \n",
       "3  2019-04-14  2019-04-28  2019-04-28  2019-04-14  2020-03-01  2019-05-05   \n",
       "4  2020-10-25  2020-10-25  2019-10-06  2020-10-25  2020-10-25  2020-10-25   \n",
       "\n",
       "  WY_max_date  \n",
       "0  2019-12-29  \n",
       "1  2019-09-01  \n",
       "2  2020-01-19  \n",
       "3  2019-04-14  \n",
       "4  2019-10-06  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_df = combo_df[cols]\n",
    "combo_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
